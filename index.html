<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>音声からドレミと楽譜</title>
  <style>
    #keyboard {
      display: flex;
      margin-top: 20px;
      height: 100px;
    }
    .key {
      width: 40px;
      border: 1px solid #000;
      background: white;
      position: relative;
      text-align: center;
      line-height: 100px;
      font-weight: bold;
      font-family: sans-serif;
    }
    .key.active {
      background: orange;
    }
    #noteList {
      white-space: pre-wrap;
      margin-top: 20px;
    }
  </style>
  <script src="https://unpkg.com/vexflow/releases/vexflow-min.js"></script>
</head>
<body>
  <input type="file" id="audioFile" accept="audio/*,.mp3,.wav" />
  <h2 id="noteDisplay">♪ ドレミ解析待ち</h2>
  <canvas id="sheet" width="800" height="200"></canvas>
  <div id="noteList"></div>
  <div id="keyboard"></div>

  <script>
    const noteNames = ["ド", "ド♯", "レ", "レ♯", "ミ", "ファ", "ファ♯", "ソ", "ソ♯", "ラ", "ラ♯", "シ"];
    const keyboardDiv = document.getElementById("keyboard");

    const midiStart = 48; // C3
    const midiEnd = 71;   // B4
    const keys = [];
    for (let midi = midiStart; midi <= midiEnd; midi++) {
      const noteName = noteNames[midi % 12];
      const key = document.createElement("div");
      key.className = "key";
      key.dataset.midi = midi;
      key.textContent = noteName;
      keyboardDiv.appendChild(key);
      keys.push(key);
    }

    function freqToNote(freq) {
      if (freq < 20 || freq > 5000) return null;
      const noteNum = 12 * Math.log2(freq / 440) + 69;
      const rounded = Math.round(noteNum);
      const name = noteNames[rounded % 12];
      const octave = Math.floor(rounded / 12) - 1;
      return { name, midi: rounded, label: `${name}${octave}` };
    }

    function highlightKey(midi) {
      keys.forEach(k => k.classList.remove("active"));
      const key = keys.find(k => parseInt(k.dataset.midi) === midi);
      if (key) key.classList.add("active");
    }

    const noteList = document.getElementById("noteList");
    const canvas = document.getElementById("sheet");
    const renderer = new Vex.Flow.Renderer(canvas, Vex.Flow.Renderer.Backends.CANVAS);
    const context = renderer.getContext();
    let stave = new Vex.Flow.Stave(10, 40, 780);
    stave.addClef("treble").setContext(context).draw();
    let currentNotes = [];

    function addNoteToSheet(note) {
      const noteNameMap = {
        "ド": "C", "ド♯": "C#", "レ": "D", "レ♯": "D#", "ミ": "E",
        "ファ": "F", "ファ♯": "F#", "ソ": "G", "ソ♯": "G#", "ラ": "A", "ラ♯": "A#", "シ": "B"
      };
      const octave = note.label.match(/\d+/)?.[0] || "4";
      const key = `${noteNameMap[note.name]}/${octave}`;
      currentNotes.push(new Vex.Flow.StaveNote({ clef: "treble", keys: [key], duration: "q" }));

      if (currentNotes.length >= 8) {
        const voice = new Vex.Flow.Voice({ num_beats: 8, beat_value: 4 });
        voice.addTickables(currentNotes);
        new Vex.Flow.Formatter().joinVoices([voice]).format([voice], 700);
        voice.draw(context, stave);
        currentNotes = [];
      }
    }

    document.getElementById('audioFile').addEventListener('change', async (e) => {
      const file = e.target.files[0];
      if (!file) return;

      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const arrayBuffer = await file.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);

      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;

      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 2048;
      const freqData = new Uint8Array(analyser.frequencyBinCount);

      source.connect(analyser);
      analyser.connect(audioContext.destination);
      source.start();

      const noteDisplay = document.getElementById("noteDisplay");
      let detectedNotes = "♪ 検出されたドレミ：\n";
      let lastMidi = -1;

      const interval = setInterval(() => {
        analyser.getByteFrequencyData(freqData);
        const maxIndex = freqData.indexOf(Math.max(...freqData));
        const freq = maxIndex * audioContext.sampleRate / analyser.fftSize;
        const note = freqToNote(freq);
        if (note && note.midi !== lastMidi) {
          noteDisplay.textContent = `♪ 今の音：${note.label}`;
          highlightKey(note.midi);
          detectedNotes += note.name + " ";
          noteList.textContent = detectedNotes;
          addNoteToSheet(note);
          lastMidi = note.midi;
        }
      }, 300);

      setTimeout(() => {
        clearInterval(interval);
        noteDisplay.textContent += "（終了）";
        keys.forEach(k => k.classList.remove("active"));
      }, audioBuffer.duration * 1000 + 500);
    });
  </script>
</body>
</html>
